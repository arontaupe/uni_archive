{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"G09_H09_D.ipynb","provenance":[{"file_id":"https://github.com/lukeeffenberger/IANNWTF-2019/blob/master/homework/homework09.ipynb","timestamp":1579029455678}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EUm0AHU8fBBL","colab_type":"text"},"source":["# Homework 09 - RNNs\n","\n","In this homework you will learn how to generate text with an RNN. \n","\n","Defining an RNN in TensorFlow is based on a specific framework. Therefore I will provide you with the correct model definition. Your task will be to to understand how the model processes sequential data, which kind of data it returns and how to train it.\n","\n","You will train a stacked RNN to generate text passages, similar to those in the bible."]},{"cell_type":"code","metadata":{"id":"DVQfoQUHfBBN","colab_type":"code","outputId":"bd5663c1-5b1d-468f-bc53-def30e2e64d5","executionInfo":{"status":"ok","timestamp":1580298051965,"user_tz":-60,"elapsed":2128,"user":{"displayName":"Sahar Niknam","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLKUj6502neMvy6tJk1YJNcYC8gSWwAHJjDwjcMQ=s64","userId":"01256590751452863625"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","import random\n","import time\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"w412XglRfBBR","colab_type":"text"},"source":["### Load text.\n","\n","1. Download the file 'bible.txt' from the folder **files/Stuff for Homework** on Stud.IP.\n","\n","2. Upload the file 'bible.txt' to you Google Drive.\n","\n","3. Run the next cell to give Colab permission to have access to your Google Drive content.\n","\n","4. Change the file path in **the cell after the next**, accordingly."]},{"cell_type":"code","metadata":{"id":"VDn3jaMWfzMF","colab_type":"code","outputId":"3560608f-4ab4-4c89-8f8f-4d753ab0285e","executionInfo":{"status":"ok","timestamp":1579620129678,"user_tz":-60,"elapsed":1096,"user":{"displayName":"Aron Petau","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCPeePOBGxdmNMtn-xdZ-ED0fb2lnBxZSxuhCZbWOo=s64","userId":"01183481903912340160"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# To give Colab permission ot access to your Google Drive run this cell\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yscaVGbvfBBS","colab_type":"code","outputId":"2c196084-2c38-4c26-f306-5090e13950be","executionInfo":{"status":"ok","timestamp":1580298080559,"user_tz":-60,"elapsed":410,"user":{"displayName":"Sahar Niknam","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLKUj6502neMvy6tJk1YJNcYC8gSWwAHJjDwjcMQ=s64","userId":"01256590751452863625"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["# Load the text.\n","txt = open(\"/content/drive/My Drive/bible.txt\",'r').read()\n","print(\"Text length: {}\".format(len(txt)))\n","print('-------------------------------------')\n","\n","# Inspect first lines:\n","print(txt[:500])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Text length: 4332496\n","-------------------------------------\n","The First Book of Moses:  Called Genesis\n","\n","\n","1:1 In the beginning God created the heaven and the earth.\n","\n","1:2 And the earth was without form, and void; and darkness was upon\n","the face of the deep. And the Spirit of God moved upon the face of the\n","waters.\n","\n","1:3 And God said, Let there be light: and there was light.\n","\n","1:4 And God saw the light, that it was good: and God divided the light\n","from the darkness.\n","\n","1:5 And God called the light Day, and the darkness he called Night.\n","And the evening and the mornin\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aepQxISUfBBW","colab_type":"code","outputId":"9c7c1618-59ee-4abd-f032-4af3d61eb5be","executionInfo":{"status":"ok","timestamp":1580298083084,"user_tz":-60,"elapsed":459,"user":{"displayName":"Sahar Niknam","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLKUj6502neMvy6tJk1YJNcYC8gSWwAHJjDwjcMQ=s64","userId":"01256590751452863625"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["# Get the vocabulary of the text\n","vocab = sorted(set(txt))\n","print(\"Vocabulary: {}\".format(vocab))\n","print('--------------------------')\n","vocab_size = len(vocab)\n","print(\"Vocabulary size: {}\".format(vocab_size))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Vocabulary: ['\\n', ' ', '!', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n","--------------------------\n","Vocabulary size: 74\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XR71bMbIfBBa","colab_type":"code","colab":{}},"source":["# Create dictionaries to switch between the indices of the characters and the characters themselves.\n","char2idx = {ch:i for i,ch in enumerate(vocab)}\n","idx2char = {i:ch for i,ch in enumerate(vocab)}\n","# Translate the text to indices.\n","txt_idx = [char2idx[ch] for ch in txt]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5PkVVMjBfBBd","colab_type":"text"},"source":["### Prepare TensorFlow dataset.\n","\n","In the following we will process the text to a suitable dataset."]},{"cell_type":"code","metadata":{"id":"fI6usVMrfBBe","colab_type":"code","colab":{}},"source":["# First create a tensorflow dataset out of the text (in indices). (tf.data.Dataset.from_tensor_slices)\n","dataset = tf.data.Dataset.from_tensor_slices(txt_idx)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kJB-IrWmfBBh","colab_type":"code","colab":{}},"source":["# We will train on subsequences of length 20 and compute the loss for each timestep.\n","# Let's think about how a single training datapoint will look.\n","# Example:\n","# Input sequence: \"Moses:  Called Genesi\"\n","# Target sequence: \"oses:  Called Genesis\"\n","# To create these pairs of sequence we chunk the dataset into subsequences of length k+1.\n","# You can use .batch() for this. \n","# And make sure that all subsequences in the resulting dataset have length k+1 (understand\n","# parameter 'drop_remainder' in .batch())\n","K = 20\n","data = dataset.batch(K+1, drop_remainder = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fLdZlYn3fBBk","colab_type":"code","colab":{}},"source":["# Now we have to map each sequence of length 21\n","# to a (input, target) pair.\n","# Given the following function you can use the dataset method .map() here.\n","def input_target_split(seq):\n","    return seq[:-1], seq[1:]\n","dataset = data.map(input_target_split)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjrIRVaxfBBm","colab_type":"code","colab":{}},"source":["# Now as usual we shuffle our dataset and chunk it into batches of 64.\n","BATCHSIZE = 64\n","BUFFERSIZE = 10000\n","dataset = dataset.shuffle(BUFFERSIZE)\n","dataset = dataset.batch(BATCHSIZE, drop_remainder=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bpAPdXSMfBBq","colab_type":"code","colab":{}},"source":["# Provided definitions of Vanilla RNN cell and RNN model.\n","\n","class VanillaRNNCell(tf.keras.layers.Layer):\n","\n","    def __init__(self, input_dim, units):\n","        super(VanillaRNNCell, self).__init__()\n","        self.input_dim = input_dim\n","        self.units = units\n","        # TF needs this.\n","        self.state_size = units\n","    \n","    def build(self, input_shape):\n","        self.w_in = self.add_weight(\n","                            shape=(self.input_dim, self.units),\n","                            initializer='uniform'\n","                            )\n","        self.w_h = self.add_weight(\n","                            shape=(self.units, self.units),\n","                            initializer='uniform'\n","                            )\n","        self.b_h = self.add_weight(\n","                            shape=(self.units,),\n","                            initializer='zeros'\n","                            )       \n","            \n","    def call(self, inputs, hidden_states):\n","        h_prev = hidden_states[0]\n","        h_new = tf.nn.sigmoid(tf.matmul(inputs, self.w_in) + tf.matmul(h_prev, self.w_h) + self.b_h)\n","        return h_new, [h_new]\n","\n","state_size_1 = 128\n","state_size_2 = 256\n","\n","class RNN(tf.keras.layers.Layer):\n","    \n","    def __init__(self):\n","        super(RNN, self).__init__()\n","        self.cell_1 = VanillaRNNCell(input_dim=vocab_size, units=state_size_1)\n","        self.cell_2 = VanillaRNNCell(input_dim=state_size_1, units=state_size_2)\n","        self.cells = [self.cell_1, self.cell_2]\n","        self.rnn = tf.keras.layers.RNN(self.cells, return_sequences=True)\n","        self.output_layer = tf.keras.layers.Dense(units=vocab_size, activation=tf.nn.softmax)\n","        \n","    def call(self,x):\n","        seqs = self.rnn(x)\n","        output = self.output_layer(seqs)\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C_BxvySXfBBu","colab_type":"code","colab":{}},"source":["# Defining the function for generating novel text samples.\n","def generate_sample(sample, n):\n","    # Translate sample string into list of characters.\n","    lis = [char2idx[s] for s in sample]\n","    # Transform list into tensor of shape (1,20,vocab_size)\n","    lis = tf.one_hot(lis, depth = vocab_size)\n","    lis = tf.expand_dims(lis, 0)\n","    # Sample n new characters.\n","    for _ in range(n):      \n","        # Feed sample sequence into RNN and get probabilities of next character.\n","        prob = model(lis)\n","        prob = tf.squeeze(prob, 0)\n","        prob = prob / WONKYNESS \n","        # Sample index for new character (use tf.random.categorical()).\n","        pred_idx = tf.random.categorical(prob, num_samples = 1)[-1,0].numpy()\n","        # Translate to actual character and add it to sample string.\n","        char = idx2char[pred_idx]\n","        sample += char\n","        # Create new sequence of 20 indices by deleting the first character of the old sequence\n","        # and adding the new character.\n","        new_sample = sample[-K:]\n","        lis = [char2idx[s] for s in new_sample]\n","        lis = tf.one_hot(lis, depth = vocab_size)\n","        lis = tf.expand_dims(lis, 0)\n","    return sample"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ObzQEH2LbM9r","colab_type":"code","colab":{}},"source":["tf.keras.backend.clear_session()\n","# Initialize the RNN, cross entropy as a loss function and as an optimizer Adam with learning rate 0.01.\n","model = RNN()\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"_9lh1etIfBBy","colab_type":"code","outputId":"31678382-ddc6-4a58-924d-006b62afeae9","executionInfo":{"status":"ok","timestamp":1580298375408,"user_tz":-60,"elapsed":156155,"user":{"displayName":"Sahar Niknam","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLKUj6502neMvy6tJk1YJNcYC8gSWwAHJjDwjcMQ=s64","userId":"01256590751452863625"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Train for one epoch. Your loss should be around 1.4.\n","# Remember to encode the inputs and target values as one hots.\n","EPOCHS = 1\n","s = time.time()\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","    for (x,targ) in dataset:\n","        x = tf.one_hot(x, depth = vocab_size)\n","        targ = tf.one_hot(targ, depth = vocab_size)\n","\n","        with tf.GradientTape() as tape:\n","            pred = model(x)\n","            batch_loss = loss(targ, pred)\n","            gradients = tape.gradient(batch_loss, model.trainable_variables)\n","        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    print(f\"Epoch: {epoch + 1} ; Loss: {batch_loss.numpy()} ; Time: {round(time.time() - start)} sec\")\n","print(f\"Total Time until completion: {round(time.time() - s)}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 1 ; Loss: 1.4544851779937744 ; Time: 154 sec\n","Total Time until completion: 154\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FV988i0IfBB2","colab_type":"code","outputId":"d4eba9b2-a62b-457c-cefa-f68f20c2b051","executionInfo":{"status":"ok","timestamp":1580298380573,"user_tz":-60,"elapsed":5134,"user":{"displayName":"Sahar Niknam","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLKUj6502neMvy6tJk1YJNcYC8gSWwAHJjDwjcMQ=s64","userId":"01256590751452863625"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# Feel free to generate some funny samples.\n","# The function should take the sample below (of length k) and generate a text sequence of length k+n from it.\n","WONKYNESS = 0.028 #Higher number makes text more unpredictable\n","#Experimentally, Values between 0.01 and 0.1 work best\n","\n","#sample = 'The First Book of Moses:  Called Genesis'\n","#sample = '1:1 God and Jesus made wine and smoked a'\n","sample = '1:1 In the beginning'\n","print(f\"Sample Length: {len(sample)} ; K : {K}\")\n","\n","assert(len(sample)==K)\n","\n","print(generate_sample(sample,200))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sample Length: 20 ; K : 20\n","1:1 In the beginning and the things and square the more the seven King 9:1z ves of the (prophets of the Dedise the seed the body of the world and the children, and the seed the world and the seven the seed the uncleannes\n"],"name":"stdout"}]}]}